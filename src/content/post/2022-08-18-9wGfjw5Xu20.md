---
showLink: "https://www.youtube.com/watch?v=9wGfjw5Xu20"
channel: "Ben Holmes"
channelURL: "https://www.youtube.com/@bholmesdev"
title: "Make servers faster with cache controls ðŸ’° #whiteboardtheweb"
description: "Caching strategies in server-side rendering optimize performance by storing pre-generated assets and minimizing response times."
publishDate: "2022-08-18"
ogImage: "https://i.ytimg.com/vi/9wGfjw5Xu20/maxresdefault.jpg"
---

## Episode Summary

tl;dr: In server-side rendering, caching strategies are crucial for optimizing performance. By setting cache headers, frequently requested pages can be served from the cache, providing near-instant responses. Assets can be cached indefinitely, and regenerated with new file names upon site rebuilds. Caching is like a bakery, where fresh batches are made and served until they become stale. Edge compute can further reduce initial response times by bringing servers closer to users.

## Chapters

00:00 - Caching Strategies in Server-Side Rendering  

The episode begins by discussing caching strategies in server-side rendering. It explains how caching can be used to minimize response times for frequently requested pages and assets, reducing the need for users to wait for each request to be processed by the server.

## Transcript

[00:00] Let's talk about caching strategies. Usually when you're server-side rendering,

[00:03] you have a server or serverless function that's going to handle all the incoming requests.

[00:08] So when a user tries to visit a URL, and our handler processes that request

[00:14] and returns a valid response in however many milliseconds. And this is okay for a bespoke request,

[00:19] but the user shouldn't have to wait 200 milliseconds or more for every single page on your site.

[00:24] We should be able to cache things ahead of time. So let's send a cache header back to the user to say,

[00:29] hey, for the next 60 seconds or one minute, use the cache version of this file

[00:33] instead of requesting another version from the server. So if I request the same page again in the next minute,

[00:39] you'll get a near instant response back with that cache version.

[00:42] You could even set the cache to a huge max age so that the file basically never expires

[00:47] and the user only requests the file once. It can be useful for generated assets

[00:51] that Next.js or Astro might output because we can cache a certain asset forever,

[00:56] then generate an asset with a new file name every time you rebuild your site.

[01:00] So you kind of get the best of both worlds. You can kind of think of caching like a bakery

[01:04] where it takes a little time to make that first batch, but these cookies are fresh for the rest of the day.

[01:09] So customers can come in and buy them. But when those cookies have gone stale,

[01:12] we can just throw them out and make a fresh batch. So we've talked about how to handle our servers,

[01:17] but how do we get our servers as close to the user as possible to cut down on that initial response time?

[01:22] That can benefit from edge compute, which we'll talk about next.

